---
layout: post
title: Apparent uselessness
---

# Apparent uselessness and the illusion of progress

*Keywords*: dominant progressivist narratives, undreamed-of-utility, robot epistemology

Sometime last year I picked up on Kenneth Stanley's and Joel Lehmann's
2015 book called "Why Greatness Cannot Be Planned - The Myth of the
Objective". In the book they develop an argument based on experiments
with synthetic processes of knowledge acquisition in the context of
AI, ALife, and Learning. So far so good, I basically completely agree
with their line of reasoning.

In the meantime, additional manifestations of that same idea keep
popping up urging the collector inside me to collect. Here we
go.

 - __2015__ Stanley and Lehmann argue that, considering results on
   "novelty search" in learning experiments with artificial agents,
   unreflected measures of the distance to a given "goal" are bound to
   get you stuck in a local extremum in all but trivial cases [^1].
 - __1939__ Abraham Flexner's article "The usefulness of useless
   knowledge" [^2], published in Harper's issue 179 June/November 1939 (available online as PDF). Flexner curiously sketches out a similar line of argument as
   Stanley and Lehmann reinvigorating satisfaction of _curiosity_ as a sufficient and ultimately fruitful guide in the pursuit of knowledge.
 - __198X__ The young field of media archaeology has been promoting the stance
   that complex techno-mathematical media can only be understood by
   reconstructing original forward-looking perspectives and
   emphasizing the genealogical importance of developments which
   became "dead media" only in hindsight.
 - __2007__ Nicholas Nassim Taleb, deserving a separate comment on the black
   swan idea (2007), meticulously expounds the difference of the
   forward and the retrospective narration and substantializes the
   phenomenon of unpredictability in the domain of complex systems (Extremistan). Honouring
   this fundamental unpredictabilty we should be highly doubtful
   about our ability to predict the future utility of any given idea.
 - This is an open list and this entry is a placeholder for things to
   come ...

Realizing the validity of this issue there are fundamental
consequences to for many areas of human activity, two of which are:
autonomous robotic learning (no universal recipe) and funding of
professional and amateur scientific pursuits (no maps for uncharted
territory [^3]).

## Footnotes

[^1]: Based on my own understanding of different learning problems for
	artificial agents there are two fundamental types of such problems:
	those in which the goal-seeker and the goal are alone in "free space",
	and those in which other objects, usually referred to as "obstacles",
	are present in the same space. In the first case, the goal can be
	reached by greedily reducing the distance on all axes of space
	independently. In the second case, already no universal recipe
	whatsoever can be given on how to reach the goal. In order to reach
	it, the distance to the goal has to increase on at least one axis of
	the given space at some point. It seems related to convexity but I leave the
	respective diagram for later.

[^2]: Thanks Giulio Sandini.

[^3]: Please describe in precise steps how you are going to reach an
	objective (draw a route on a map), which at best is likely to exist
	and usually is only a vision, and where no one has gone before (on
	parts of the map labelled "Terra incognita").

